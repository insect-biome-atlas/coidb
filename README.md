[![Pixi Badge](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/prefix-dev/pixi/main/assets/badge/v0.json)](https://pixi.sh)

# COI DB

## Overview

The coidb package runs a Snakemake workflow under the hood which contains steps
to filter the BOLD public data to only the COI-5P marker gene, remove leading
and trailing gaps and sequences with internal gaps and ambiguous nucleotides. It
also applies a length filtering and only keeps records assigned to a BOLD BIN.
Records assigned to prokaryotes are however kept even if they are lacking BOLD
BIN assignment. The filtered sequences are then dereplicated by clustering
sequences within each BOLD BIN using vsearch. 

Missing taxonomic labels are filled by taking the lowest assigned taxonomy and
adding a '_X' suffix with an 'X' for each downstream rank with missing taxonomy.

For example, a record with: 

| processid  | kingdom  | phylum     | class     | order   | family    | genus | species | bin_uri      |
|------------|----------|------------|-----------|---------|-----------|-------|---------|--------------|
| AAPY056-10 | Animalia | Arthropoda | Arachnida | Araneae | Araneidae |       |         | BOLD:AAM5892 |


becomes:

| processid  | kingdom  | phylum     | class     | order   | family    | genus       | species      | bin_uri      |
|------------|----------|------------|-----------|---------|-----------|-------------|--------------|--------------|
| AAPY056-10 | Animalia | Arthropoda | Arachnida | Araneae | Araneidae | Araneidae_X | Araneidae_XX | BOLD:AAM5892 |

A consensus taxonomy for each BIN is then generated by downloading the [GBIF
backbone taxonomy](https://hosted-datasets.gbif.org/datasets/backbone/current/).
If BINs are not present in the GBIF backbone, a consensus is calculated using an
80% consensus threshold starting from species and moving up in the taxonomy
tree. 

Finally, fasta and tab separated files compatible with SINTAX, DADA2 and QIIME2 are generated.

## Installation

### Install with pixi from source

1. First install [pixi](https://pixi.sh/latest/#installation)

```bash
curl -fsSL https://pixi.sh/install.sh | sh
```

2. Then clone the GitHub repository and change into the `coidb` directory

```bash
git clone git@github.com:insect-biome-atlas/coidb.git
cd coidb
```

3. Install the `coidb` package with pixi and start a shell in the installed environment

```bash
pixi shell
```

If the installation worked you should be able to run `coidb -h`. Proceed to the [Configuration]() section to see how to configure coidb.

### Install with Conda

1. Make sure [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html) is installed on your system.

2. Create a new environment with `coidb` installed:

```bash
conda create -n coidb -c bioconda coidb
```

3. Activate the `coidb` environment:

```bash
conda activate coidb
```

## Running coidb

The general syntax for running `coidb` is:

```bash
coidb run <arguments>
```

To see a list of all arguments, run `coidb run -h`. The available arguments are listed below:

```bash
--input-file       -i PATH        Input tar.gz archive dowloaded from BOLD.
--output-dir       -o PATH        Folder to store database files in [default: results]
--account          -A TEXT        SLURM compute account [default: None]
--temp-dir            PATH        Folder for temporary files [default: tmp]
--gbif-backbone                   Use GBIF backbone to infer consensus taxonomy for BOLD BINs
--consensus-threshold INTEGER     Threshold (in %) when calculating consensus taxonomy [default: 80]
--consensus-method    [rank|full] Method to use when calculating consensus [default: rank]
--vsearch-identity    FLOAT       Identity at which to cluster sequences per BIN [default: 1.0]
--ranks               TEXT        Ranks to use for calculating consensus and generating fastas [default: kingdom, phylum, class, order, family, genus, species]
--min-len             INTEGER     Minimum length of sequences to include [default: 500]
```

* The `--input-file` `-i` argument must point to a BOLD tar archive that you
  have downloaded from [boldsystems.org](https://boldsystems.org/) (see [Obtain
  data](#obtain-data) below). 
* The `--output-dir` or `-o` argument is a directory in which the output from
  `coidb` will be stored (see details under [Output](#output) below).
* The `--account` or `-A` argument sets a compute account for running on SLURM
  clusters (see [Cluster execution](#cluster-execution) below).
* The `--temp-dir` argument sets a directory to use for storing temporary
  output. This directory can be deleted once `coidb` finishes.
* The `--gbif-backbone` argument instructs `coidb` to use the GBIF backbone
  taxonomy to infer taxonomic information for BOLD BINs. Note that this option
  is currently not reliable because of outdated GBIF data.
* The `--consensus-threshold` specifies a threshold in percent when calculating
  consensus taxonomies for BOLD BINs. 
* The `--consensus-method` argument specifies how the consensus taxonomy is
  calculated. With `rank` (default), a consensus is calculated at each rank
  separately starting from 'species' and moving up in the hierarchy (genus,
  family etc.). If a consensus above the consensus-threshold is found at any
  rank, the taxonomy at that rank and its parent lineage is used as taxonomy for
  the BOLD BIN. With `full`, a consensus is applied by taking into account the
  parent lineages at each rank, so starting with all labels from
  kingdom->species, then kingdom->genus etc.
* The `--vsearch-identity` argument specifies the identity threshold to use when
  clustering sequences with vsearch. The default is `1.0` meaning sequences are
  clustered at 100% identity.
* The `--ranks` argument specifies what taxonomic ranks to use. This applies
  both to what ranks are included in the final output and what ranks are used to
  calculate the consensus taxonomy.
* The `--min-len` argument sets a minimum length for sequences to include in the
  final output.

In addition to these command line arguments there are some arguments that define how `coidb` runs on your system and which are similar to how you typically interact with Snakemake workflows:

```bash
--config             FILE     Path to snakemake config file. Overrides existing workflow configuration. [default: None] 
--resource        -r PATH     Additional resources to copy from workflow directory at run time.
--profile         -p TEXT     Name of profile to use for configuring Snakemake. [default: None]
--dry             -n          Do not execute anything, and display what would be done.
--lock            -l          Lock the working directory.
--dag             -d PATH     Save directed acyclic graph to file. Must end in .pdf, .png or .svg [default: None]
--cores           -c INTEGER  Set the number of cores to use. If None will use all cores. [default: None]
--no-conda.                   Do not use conda environments.
--keep-resources              Keep resources after pipeline completes.
--keep-snakemake              Keep .snakemake folder after pipeline completes.
--verbose         -v          Run workflow in verbose mode.
--help-snakemake  -hs         Print the snakemake help and exit.
--help            -h                Show this message and exit.
```

* The `--config` argument lets you pass a configuration file in YAML format, as
  an alternative to specifying arguments directly on the command line.
* The `--profile` argument specifies configuration profile to use for running `coidb`.

### Obtain data

The coidb package uses public barcode reference libraries from [BOLD](https://bench.boldsystems.org/index.php) to build reference fasta files compatible with tools like SINTAX, QIIME2 and DADA2. The first thing you need to do is get your hands on a BOLD Public Data Package:

1. Go to the BOLD systems [data package page](https://bench.boldsystems.org/index.php/datapackages/Latest).
2. Login is required to access files on this page, so either login or sign up if you don't already have an account.
3. On the data package page, click the **Data package (tar.gz compressed)** download button, accept the terms and click **Download** to obtain a temporary download link.
4. Use the link to download the data package which will be named `BOLD_Public.<dd>-<Mmm>-<YYYY>.tar.gz`, for example `BOLD_Public.20-Jun-2025.tar.gz`.

> [!TIP]
> To download via the command line you can copy the Download link instead of clicking it, then use `wget` or `curl` to download directly to a file of your choice. For example, to download the data package to a directory called `data/` you could run:
> ```bash
> mkdir data
> wget -O data/BOLD_Public.20-Jun-2025.tar.gz <copied download link>
> ```
> or with `curl`:
> ```bash
> mkdir data 
> curl -o data/BOLD_Public.20-Jun-2025.tar.gz <copied download link>
> ```

The downloaded file can now be used as input to `coidb` by pointing to it with the `--input-file` argument, or by setting `input_file: <path-to-downloaded-tar.gz file>` in a [configuration file](#using-a-configuration-file)

BOLD citation:

Ratnasingham, Sujeevan, and Paul D N Hebert. “bold: The Barcode of Life Data System (http://www.barcodinglife.org).” Molecular ecology notes vol. 7,3 (2007): 355-364. doi:10.1111/j.1471-8286.2007.01678.x

### Using a configuration file

You can generate a default configuration file by running:

```bash
coidb config > config.yml
```

This creates a new file `config.yml` with the following default parameters:

```yaml
account: null
consensus_method: rank
consensus_threshold: 80
gbif_backbone: false
input_file: null
min_len: 500
output_dir: results
ranks:
- kingdom
- phylum
- class
- order
- family
- genus
- species
temp_dir: tmp
vsearch_identity: 1.0
```

You can then edit this file and use it with coidb like so:

```bash
coidb run --config config.yml
```


### Cluster execution

To run `coidb` on a compute cluster you must set the compute account to use with
the `--account` or `-A` argument. In addition, you should use one of the
pre-defined configuration profiles. To see available profiles, run:

```bash
coidb profile list
```

The profiles can be used as-is by adding `--profile <name of profile>` to the
command line call, or you can output the settings for a profile to a file and
modify it you fit your needs. For example, to output the generic SLURM profile
settings, we recommend that you run:

```bash
mkdir my-slurm-profile
coidb profile show slurm > my-slurm-profile/config.yaml
```

Then you can edit the `my-slurm-profile/config.yaml`. Once you're done you can
use this profile by passing `--profile my-slurm-profile` to the `coidb run`
command.

...

## Running coidb

The general syntax for running `coidb` is:

```bash
coidb run --input-file </path/to/input> --
```

### Configuration

In order to run `coidb` you need to [obtain a data file](#obtain-data) and
modify the `input_file:` parameter so that it points to the downloaded
`*.tar.gz` data file, _e.g._:

```yaml
input_file: '<path-to-download>.tar.gz'
```

## Output

The primary outputs of the tool are:

1. bold_clustered_cleaned.fasta: A fasta file with sequences clustered at whatever threshold set in the config file (default is 1.0 which means 100% identity). The header of each sequence in this file has the format

```
>GMGMN070-14 Animalia;Arthropoda;Insecta;Lepidoptera;Pieridae;Gonepteryx;Gonepteryx rhamni;BOLD:AAA9222
```

In this example `GMGMN070-14` is the representative id for the sequence and can be viewed in the BOLD database at https://www.boldsystems.org/index.php/Public_RecordView?processid=GMGMN070-14.

2. bold_clustered.sintax.fasta: This fasta file is compatible with the SINTAX classification tool implemented in [vsearch](https://github.com/torognes/vsearch) and has headers with the format:

```
>GMGMN070-14;tax=d:Animalia,k:Arthropoda,p:Insecta,c:Lepidoptera,o:Pieridae,f:Gonepteryx,g:Gonepteryx rhamni,s:BOLD:AAA9222
```

> [!NOTE]
> In the SINTAX formatted headers, the taxonomic ranks are shifted to allow classification down to BOLD_bin. Since SINTAX only allows for ranks prefixed with 'd' (for domain) 'k' (kingdom), 'p' (phylum), 'c' (class), 'o' (order), 'f' (family), 'g' (genus), or 's' (species) we shift the taxonomy so that kingdom becomes domain, etc., and prefix the BOLD bin id with 's'.

3. bold_clustered.assigntaxonomy.fasta and bold_clustered.addSpecies.fasta: These fasta files are compatible with the assignTaxonomy and addSpecies functions implemented in [DADA2](https://github.com/benjjneb/dada2/). For the assignTaxonomy file the headers have the format:

```
>Animalia;Arthropoda;Insecta;Lepidoptera;Pieridae;Gonepteryx;Gonepteryx rhamni;
```

and for the addSpecies file the headers have the format:

```
>GMGMN070-14 Gonepteryx rhamni
```

## Configuration
There are a few configurable parameters that modifies how sequences are filtered
and clustered. You can modify these parameters using a config file in `yaml` 
format. The default setup looks like this:

```yaml
database:
    # url to download info and sequence files from
    url: "https://hosted-datasets.gbif.org/ibol/ibol.zip"
    # gene of interest (will be used to filter sequences)
    gene:
        - "COI-5P"
    # phyla of interest (omit this in order to include all phyla)
    phyla: []
    # Percent identity to cluster seqs in the database by
    pid: 1.0
```

### Gene types
By default, only sequences named 'COI-5P' are included in the 
final output. To modify this behaviour you can supply a config file in `yaml`
format via `-c <path-to-configfile.yaml>`. For example, to also include 
'COI-3P' sequences you can create a config file, _e.g._ named `config.yaml` with 
these contents:

```yaml
database:
  gene:
    - 'COI-5P'
    - 'COI-3P' 
```

Then run `coidb` as:

```bash
coidb -c config.yaml
```

### Phyla

The default is to include sequences from all taxa. However, you can filter the 
resulting sequences to only those from one or more phyla. For instance, to only
include sequences from the phyla 'Arthropoda' and 'Chordata' you supply a 
config file with these contents:

```yaml
database:
  phyla:
    - 'Arthropoda'
    - 'Chordata' 
```

### Clustering

After sequences have been filtered to the genes and phyla of interest they are
clustered on a per-species (or BOLD `BIN` id where applicable) basis using 
`vsearch`. By default this clustering is performed at 100% identity. To change
this behaviour, to _e.g._ 95% identity make sure your config file contains:

```yaml
database:
  pid: 0.95
```

## Command line options

The `coidb` tool is a wrapper for a small snakemake workflow that handles
all the downloading, filtering and clustering.

```
usage: coidb [-h] [-n] [-j CORES] [-f] [-u] [-c [CONFIG_FILE ...]] [--cluster-config CLUSTER_CONFIG] [--workdir WORKDIR] [-p] [-t]
             [targets ...]

positional arguments:
  targets               File(s) to create or steps to run. If omitted, the full pipeline is run.

options:
  -h, --help            show this help message and exit
  -n, --dryrun          Only print what to do, don't do anything [False]
  -j CORES, --cores CORES
                        Number of cores to run with [4]
  -f, --force           Force workflow run
  -u, --unlock          Unlock working directory
  -c [CONFIG_FILE ...], --config-file [CONFIG_FILE ...]
                        Path to configuration file
  --cluster-config CLUSTER_CONFIG
                        Path to cluster config (for running on SLURM)
  --workdir WORKDIR     Working directory. Defaults to current dir
  -p, --printshellcmds  Print shell commands
  -t, --touch           Touch output files (mark them up to date without really changing them) instead of running their commands.
```

## How it works

Firstly sequence and taxonomic information for records in the BOLD database is 
downloaded from the [GBIF Hosted Datasets](https://hosted-datasets.gbif.org/ibol/).
GBIF processes taxonomic information from BOLD in order to resolve ambiguous 
assignments for BOLD BINs. When there are conflicting assignments at a taxonomic 
rank an 80% consensus rule is applied to keep _e.g._ a species level assignment
if four out of five names in the BIN are equal [Kõljalg et al 2020](https://www.mdpi.com/2076-2607/8/12/1910/htm).
This data is then filtered to only keep records annotated as 'COI-5P' and assigned
to a BIN ID and duplicate entries are removed. 

#### Taxonomy
The taxonomic information obtained from GBIF is then parsed in order to extract
species names to BOLD BINs. This is done by:
1. find all BOLD BINs with a taxonomic assignment at genus level, these likely have
species names assigned from GBIF (see methods for species assignment [here](https://www.mdpi.com/2076-2607/8/12/1910/htm))
2. obtain all parent taxonomic ids for BOLD BINs from step 1 and use these to 
look up the species name for the BOLD BINs. 
3. For BOLD BINs where species name look-up failed in step 2, try to obtain 
species name using the [GBIF API](https://www.gbif.org/developer/summary).

The taxonomic data is then searched for rows where missing values for ranks are 
filled with the last known higher level rank, suffixed with `_X`. For instance,

| BOLD BIN     | kingdom   | phylum          | class | order       | family | genus | species |
|--------------|-----------|-----------------|-------|-------------|--------|-------|---------|
| BOLD:ACX1129 | Animalia  | Platyhelminthes | NaN   | Polycladida | NaN    | NaN   | NaN     |
| BOLD:ACX6548 | Chromista | Ochrophyta      | NaN   | NaN         | NaN    | NaN   | NaN     |

becomes:

| BOLD BIN     | kingdom   | phylum          | class             | order         | family         | genus           | species          |
|--------------|-----------|-----------------|-------------------|---------------|----------------|-----------------|------------------|
| BOLD:ACX1129 | Animalia  | Platyhelminthes | Platyhelminthes_X | Polycladida   | Polycladida_X  | Polycladida_XX  | Polycladida_XXX  |
| BOLD:ACX6548 | Chromista | Ochrophyta      | Ochrophyta_X      | Ochrophyta_XX | Ochrophyta_XXX | Ochrophyta_XXXX | Ochrophyta_XXXXX |

As you can see, an `X` is appended for each downstream rank with a missing assignment.

BOLD BINs are then screened for cases where there are more than 1 unique parent 
lineage for the same taxonomic assignment. For example, the following taxonomic 
information may be found for BOLD BINs with assignment 'Aphaenogaster' at the
genus level.

| kingdom  | phylym     | class       | order         | family        | genus         |
|----------|------------|-------------|---------------|---------------|---------------|
| Animalia | Animalia_X | Animalia_XX | Animalia_XXX  | Animalia_XXXX | Aphaenogaster |
| Animalia | Arthropoda | Insecta     | Hymenoptera   | Formicidae    | Aphaenogaster |               

A check is first made to see if unique parent lineages can be obtained by 
removing BINs that only have missing assignments for parent ranks up to and including 
phylum. If that doesn't result in a unique parent lineage, the conflicting rank
assignments are prefixed with the lowest assigned parent rank. 

For example, BOLD BINs with genus level assignment 'Paralagenidium' have both 
`k_Chromista;p_Oomycota;c_Peronosporea;o_Peronosporales;f_Pythiaceae` and 
`k_Chromista;p_Ochrophyta;c_Ochrophyta_X;o_Ochrophyta_XX;f_Ochrophyta_XXX` as parent
lineages. Since these conflicts cannot be resolved by removing BINs (all BINs have
assignments at phylum level), the taxa labels at genus and species level are prefixed
with either `Pythiaceae_` or `Ochrophyta_XXX_`.

#### Sequence processing
Sequences are then processed to remove gap characters and leading and trailing 
`N`s. After this, any sequences with remaining non-standard characters are removed.
Sequences are then clustered at 100% identity using [vsearch](https://github.com/torognes/vsearch) 
(Rognes _et al._ 2016). This clustering is done separately for sequences assigned 
to each BIN ID.   

### Step-by-step

You can also run the `coidb` tool in steps, _e.g._ if you are only interested
in some of the files or if you want to inspect the results before proceeding 
to the next step. This is done using the positional argument `targets`. 

Valid targets are `download`, `filter` and `cluster`. 

#### Step 1: Download
For example, to only
download files from GBIF you can run:

```bash
coidb download
```

This should produce two files `bold_info.tsv` and `bold_seqs.txt` containing
metadata and nucleotide sequences, respectively.

#### Step 2: Filter

To also filter the `bold_info.tsv` and `bold_seqs.txt` files (according to the 
default 'COI-5P' gene or any other genes/phyla you've defined in the optional 
config file) you can run:

```bash
coidb filter
```

This filters sequences in `bold_seqs.txt` and entries in `bold_info.tsv` to 
potential genes and phyla of interest, respectively. Entries are then merged
so that only sequences with relevant information are kept. Output files from
this step are `bold_filtered.fasta` and `bold_info_filtered.tsv`.


#### Step 3: Clustering

The final step clusters sequences in `bold_filtered.fasta` on a per-species 
basis. This means that for each species, the sequences are gathered, 
clustered with `vsearch` and only the representative sequences are kept. In this 
step sequences can either have a species name or a BOLD `BIN` ID 
(_e.g._ `BOLD:AAY5017`) and are treated as being equivalent.

To run the clustering step, do:

```bash
coidb cluster
```

The end result is a file `bold_clustered.fasta`.

#### Step 4: Clean headers

The `clean` step removes extra information from sequence headers generated as part of clustering. To run this step, do:

```bash
coidb clean
```

#### Step 5: Generate SINTAX/DADA2 formatted fasta

To also get the SINTAX and/or DADA2 formatted fasta file, do:

```bash
coidb format_sintax
```

or 

```bash
coidb format_dada2
```